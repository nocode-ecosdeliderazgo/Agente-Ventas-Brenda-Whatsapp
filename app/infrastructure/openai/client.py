"""
Cliente OpenAI para integraci√≥n con GPT-4o-mini.
Maneja an√°lisis de intenci√≥n, extracci√≥n de informaci√≥n y generaci√≥n de respuestas.
"""
import logging
import json
from typing import Dict, Any, Optional
from openai import AsyncOpenAI

from app.config import settings
from prompts.agent_prompts import (
    get_intent_analysis_prompt,
    get_information_extraction_prompt,
    get_response_generation_prompt,
    PromptConfig
)

logger = logging.getLogger(__name__)


class OpenAIClient:
    """
    Cliente especializado para interacciones con OpenAI GPT-4o-mini.
    
    Responsabilidades:
    - An√°lisis de intenci√≥n de mensajes
    - Extracci√≥n de informaci√≥n de usuarios
    - Generaci√≥n de respuestas inteligentes
    - Manejo de errores y configuraci√≥n
    """
    
    def __init__(self):
        """Inicializa el cliente OpenAI con configuraci√≥n."""
        if not settings.openai_api_key:
            raise ValueError("OPENAI_API_KEY no est√° configurada")
        
        self.client = AsyncOpenAI(
            api_key=settings.openai_api_key
        )
        self.logger = logging.getLogger(__name__)
    
    async def analyze_intent(
        self,
        user_message: str,
        user_memory,
        recent_messages: Optional[list] = None
    ) -> Dict[str, Any]:
        """
        Analiza la intenci√≥n del mensaje del usuario.
        
        Args:
            user_message: Mensaje del usuario a analizar
            user_memory: Memoria del usuario con contexto
            recent_messages: Mensajes recientes para contexto
            
        Returns:
            Dict con an√°lisis de intenci√≥n estructurado
        """
        try:
            prompt = get_intent_analysis_prompt(user_message, user_memory, recent_messages)
            config = PromptConfig.get_config('intent_analysis')
            
            self.logger.info(f"üîç Analizando intenci√≥n: '{user_message[:50]}...'")
            
            response = await self.client.chat.completions.create(
                model=config['model'],
                temperature=config['temperature'],
                max_tokens=config['max_tokens'],
                messages=[
                    {"role": "system", "content": "Eres un analizador de intenci√≥n experto. Responde SOLO con JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ]
            )
            
            content = response.choices[0].message.content.strip()
            
            # Intentar parsear JSON
            try:
                intent_data = json.loads(content)
                self.logger.info(f"‚úÖ Intenci√≥n detectada: {intent_data.get('category', 'UNKNOWN')}")
                return intent_data
            except json.JSONDecodeError as e:
                self.logger.error(f"‚ùå Error parseando JSON de intenci√≥n: {e}")
                self.logger.error(f"Respuesta recibida: {content}")
                
                # Fallback con intenci√≥n gen√©rica
                return {
                    "category": "GENERAL_QUESTION",
                    "confidence": 0.5,
                    "should_ask_more": False,
                    "key_topics": ["general"],
                    "response_focus": "Responder de manera √∫til y amigable",
                    "recommended_action": "continue_conversation",
                    "urgency_level": "medium"
                }
                
        except Exception as e:
            self.logger.error(f"üí• Error en an√°lisis de intenci√≥n: {e}")
            # Fallback para asegurar que el bot funcione
            return {
                "category": "GENERAL_QUESTION",
                "confidence": 0.3,
                "should_ask_more": False,
                "key_topics": ["error"],
                "response_focus": "Responder de manera amigable",
                "recommended_action": "continue_conversation",
                "urgency_level": "low"
            }
    
    async def extract_information(
        self,
        user_message: str,
        user_memory
    ) -> Dict[str, Any]:
        """
        Extrae informaci√≥n relevante del mensaje del usuario.
        
        Args:
            user_message: Mensaje del usuario
            user_memory: Contexto previo del usuario
            
        Returns:
            Dict con informaci√≥n extra√≠da estructurada
        """
        try:
            prompt = get_information_extraction_prompt(user_message, user_memory)
            config = PromptConfig.get_config('information_extraction')
            
            self.logger.info(f"üìä Extrayendo informaci√≥n de: '{user_message[:50]}...'")
            
            response = await self.client.chat.completions.create(
                model=config['model'],
                temperature=config['temperature'],
                max_tokens=config['max_tokens'],
                messages=[
                    {"role": "system", "content": "Eres un extractor de informaci√≥n experto. Responde SOLO con JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ]
            )
            
            content = response.choices[0].message.content.strip()
            
            try:
                extracted_data = json.loads(content)
                self.logger.info(f"‚úÖ Informaci√≥n extra√≠da exitosamente")
                return extracted_data
            except json.JSONDecodeError as e:
                self.logger.error(f"‚ùå Error parseando JSON de extracci√≥n: {e}")
                return {}
                
        except Exception as e:
            self.logger.error(f"üí• Error en extracci√≥n de informaci√≥n: {e}")
            return {}
    
    async def generate_response(
        self,
        user_message: str,
        user_memory,
        intent_analysis: Dict[str, Any],
        context_info: str = ""
    ) -> str:
        """
        Genera una respuesta inteligente basada en intenci√≥n y contexto.
        
        Args:
            user_message: Mensaje del usuario
            user_memory: Memoria del usuario
            intent_analysis: Resultado del an√°lisis de intenci√≥n
            context_info: Informaci√≥n adicional de contexto
            
        Returns:
            Respuesta generada por GPT-4o-mini
        """
        try:
            prompt = get_response_generation_prompt(
                user_message, user_memory, intent_analysis, context_info
            )
            config = PromptConfig.get_config('main_agent')
            
            self.logger.info(f"üí¨ Generando respuesta para categor√≠a: {intent_analysis.get('category', 'UNKNOWN')}")
            
            response = await self.client.chat.completions.create(
                model=config['model'],
                temperature=config['temperature'],
                max_tokens=config['max_tokens'],
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            generated_response = response.choices[0].message.content.strip()
            
            # Validar que la respuesta no est√© vac√≠a
            if not generated_response:
                self.logger.warning("‚ö†Ô∏è Respuesta vac√≠a de OpenAI, usando fallback")
                return self._get_fallback_response(intent_analysis.get('category'))
            
            self.logger.info(f"‚úÖ Respuesta generada: {len(generated_response)} caracteres")
            return generated_response
            
        except Exception as e:
            self.logger.error(f"üí• Error generando respuesta: {e}")
            # Fallback para asegurar que siempre responda algo
            return self._get_fallback_response(intent_analysis.get('category', 'GENERAL_QUESTION'))
    
    def _get_fallback_response(self, category: str) -> str:
        """
        Genera respuesta de fallback seg√∫n la categor√≠a.
        
        Args:
            category: Categor√≠a de intenci√≥n detectada
            
        Returns:
            Respuesta de fallback apropiada
        """
        fallback_responses = {
            'FREE_RESOURCES': """¬°Por supuesto! üìö
            
Te voy a compartir algunos recursos gratuitos que te van a ayudar mucho.

¬øTe gustar√≠a que tambi√©n te cuente sobre nuestro curso completo?""",
            
            'EXPLORATION': """¬°Excelente pregunta! üéØ

Me encanta que est√©s explorando c√≥mo la IA puede ayudarte.

¬øEn qu√© √°rea espec√≠fica te gustar√≠a enfocarte? ¬øMarketing, automatizaci√≥n, an√°lisis de datos?""",
            
            'OBJECTION_PRICE': """Entiendo perfectamente tu preocupaci√≥n por la inversi√≥n. üí∞

Lo que me gusta es que veas esto como una inversi√≥n, no como un gasto.

¬øTe gustar√≠a que conversemos sobre el retorno de inversi√≥n que puedes esperar?""",
            
            'CONTACT_REQUEST': """¬°Perfecto! üë•

Te voy a conectar directamente con uno de nuestros asesores especializados.

¬øEst√°s listo/a para que iniciemos el contacto?""",
            
            'GENERAL_QUESTION': """¬°Excelente pregunta! üòä

Me encanta tu curiosidad sobre la IA.

¬øEn qu√© puedo ayudarte espec√≠ficamente? ¬øTe interesa automatizar alg√∫n proceso en particular?"""
        }
        
        return fallback_responses.get(category, """¬°Hola! üëã

Gracias por escribir. Estoy aqu√≠ para ayudarte con todo lo relacionado a nuestros cursos de IA.

¬øEn qu√© puedo asistirte hoy?""")
    
    async def analyze_and_respond(
        self,
        user_message: str,
        user_memory,
        recent_messages: Optional[list] = None,
        context_info: str = ""
    ) -> Dict[str, Any]:
        """
        Proceso completo: analiza intenci√≥n y genera respuesta.
        
        Args:
            user_message: Mensaje del usuario
            user_memory: Memoria del usuario
            recent_messages: Mensajes recientes
            context_info: Informaci√≥n de contexto
            
        Returns:
            Dict con an√°lisis e informaci√≥n extra√≠da y respuesta generada
        """
        try:
            # 1. Analizar intenci√≥n
            intent_analysis = await self.analyze_intent(
                user_message, user_memory, recent_messages
            )
            
            # 2. Extraer informaci√≥n (en paralelo)
            extracted_info = await self.extract_information(
                user_message, user_memory
            )
            
            # 3. Generar respuesta basada en intenci√≥n
            response = await self.generate_response(
                user_message, user_memory, intent_analysis, context_info
            )
            
            return {
                'intent_analysis': intent_analysis,
                'extracted_info': extracted_info,
                'response': response,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"üí• Error en proceso completo: {e}")
            return {
                'intent_analysis': {'category': 'GENERAL_QUESTION', 'confidence': 0.3},
                'extracted_info': {},
                'response': self._get_fallback_response('GENERAL_QUESTION'),
                'success': False,
                'error': str(e)
            }